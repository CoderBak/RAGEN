defaults:
  - base

actor_rollout_ref:
  actor:
    use_kl_loss: False


critic:
  ppo_mini_batch_size: null # by default, ppo_mini_batch_size = train_batch_size / 4
  ppo_micro_batch_size_per_gpu: null # following micro_batch_size_per_gpu
  model:
    path: ${actor_rollout_ref.model.path}
  optim:
    betas: [0.9, 0.999]

algorithm:
  gamma: 1.0
  lam: 1.0
  adv_estimator: gae
  kl_penalty: kl  # how to estimate kl divergence
  kl_ctrl:
    type: fixed
    kl_coef: 0.001